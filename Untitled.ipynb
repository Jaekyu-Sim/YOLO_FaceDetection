{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from datasets import data as dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO():\n",
    "    def __init__(self, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.input_image_width = 416\n",
    "        self.input_image_height = 416\n",
    "        self.input_image_channel = 3\n",
    "        self.num_anchors = 5\n",
    "        self.num_classes = 1\n",
    "        self.parameter()\n",
    "        #self.network(self.image)\n",
    "        root_dir = os.path.join('data/face/') # FIXME\n",
    "        self.train_path = os.path.join(root_dir, 'train')\n",
    "        self.anchors = dataset.load_json(os.path.join(self.train_path, 'anchors.json'))\n",
    "        \n",
    "        #self.yolo_loss()\n",
    "        \n",
    "    def parameter(self):\n",
    "        self.image = tf.placeholder(shape = [None, self.input_image_width, self.input_image_height, self.input_image_channel], dtype=tf.float32)\n",
    "        self.label = tf.placeholder(shape = [None, 13, 13, self.num_anchors, 6], dtype=tf.float32)\n",
    "        \n",
    "    def network(self, input_image):\n",
    "        #Layer 1 : 416, 416, 3 -> 208, 208, 32\n",
    "        L1 = tf.layers.conv2d(inputs = input_image, filters = 32, kernel_size = [3, 3], strides = (1, 1), padding = \"SAME\")\n",
    "        Y1 = tf.layers.batch_normalization(L1)\n",
    "        Y1 = tf.nn.leaky_relu(Y1, alpha = 0.1)\n",
    "        Y1 = tf.layers.max_pooling2d(Y1, pool_size = (2, 2), strides = (2, 2))\n",
    "        print(\"L1's shape : \", np.shape(Y1))\n",
    "        \n",
    "        #Layer 2 : 208, 208, 32 -> 104, 104, 128\n",
    "        L2 = tf.layers.conv2d(inputs = Y1, filters = 128, kernel_size = [3, 3], strides = (1, 1), padding = \"SAME\")\n",
    "        Y2 = tf.layers.batch_normalization(L2)\n",
    "        Y2 = tf.nn.leaky_relu(Y2, alpha = 0.1)\n",
    "        Y2 = tf.layers.max_pooling2d(Y2, pool_size = (2, 2), strides = (2, 2))\n",
    "        print(\"L2's shape : \", np.shape(Y2))\n",
    "        \n",
    "        #Layer 3 : 104, 104, 128 -> 104, 104, 64\n",
    "        L3 = tf.layers.conv2d(inputs = Y2, filters = 64, kernel_size = [3, 3], strides = (1, 1), padding = \"SAME\")\n",
    "        Y3 = tf.layers.batch_normalization(L3)\n",
    "        Y3 = tf.nn.leaky_relu(Y3, alpha = 0.1)\n",
    "        print(\"L3's shape : \", np.shape(Y3))\n",
    "        \n",
    "        #Layer 4 : 104, 104, 64 -> 52, 52, 128\n",
    "        L4 = tf.layers.conv2d(inputs = Y3, filters = 128, kernel_size = [3, 3], strides = (1, 1), padding = \"SAME\")\n",
    "        Y4 = tf.layers.batch_normalization(L4)\n",
    "        Y4 = tf.nn.leaky_relu(Y4, alpha = 0.1)\n",
    "        Y4 = tf.layers.max_pooling2d(Y4, pool_size = (2, 2), strides = (2, 2))\n",
    "        print(\"L4's shape : \", np.shape(Y4))\n",
    "        \n",
    "        #Layer 5 : 52, 52, 128 -> 52, 52, 256        \n",
    "        L5 = tf.layers.conv2d(inputs = Y4, filters = 256, kernel_size = [3, 3], strides = (1, 1), padding = \"SAME\")\n",
    "        Y5 = tf.layers.batch_normalization(L5)\n",
    "        Y5 = tf.nn.leaky_relu(Y5, alpha = 0.1)\n",
    "        print(\"L5's shape : \", np.shape(Y5))\n",
    "        \n",
    "        #Layer 6 : 52, 52, 256 -> 52, 52, 128        \n",
    "        L6 = tf.layers.conv2d(inputs = Y5, filters = 128, kernel_size = [3, 3], strides = (1, 1), padding = \"SAME\")\n",
    "        Y6 = tf.layers.batch_normalization(L6)\n",
    "        Y6 = tf.nn.leaky_relu(Y6, alpha = 0.1)\n",
    "        print(\"L6's shape : \", np.shape(Y6))\n",
    "        \n",
    "        #Layer 7 : 52, 52, 128 -> 26, 26, 256        \n",
    "        L7 = tf.layers.conv2d(inputs = Y6, filters = 256, kernel_size = [3, 3], strides = (1, 1), padding = \"SAME\")\n",
    "        Y7 = tf.layers.batch_normalization(L7)\n",
    "        Y7 = tf.nn.leaky_relu(Y7, alpha = 0.1)\n",
    "        Y7 = tf.layers.max_pooling2d(Y7, pool_size = (2, 2), strides = (2, 2))\n",
    "        print(\"L7's shape : \", np.shape(Y7))\n",
    "        \n",
    "        #Layer 8 : 26, 26, 256 -> 26, 26, 512        \n",
    "        L8 = tf.layers.conv2d(inputs = Y7, filters = 512, kernel_size = [3, 3], strides = (1, 1), padding = \"SAME\")\n",
    "        Y8 = tf.layers.batch_normalization(L8)\n",
    "        Y8 = tf.nn.leaky_relu(Y8, alpha = 0.1)\n",
    "        print(\"L8's shape : \", np.shape(Y8))\n",
    "        \n",
    "        #Layer 9 : 26, 26, 512 -> 26, 26, 256        \n",
    "        L9 = tf.layers.conv2d(inputs = Y8, filters = 256, kernel_size = [3, 3], strides = (1, 1), padding = \"SAME\")\n",
    "        Y9 = tf.layers.batch_normalization(L9)\n",
    "        Y9 = tf.nn.leaky_relu(Y9, alpha = 0.1)\n",
    "        print(\"L9's shape : \", np.shape(Y9))\n",
    "        \n",
    "        #Layer 10 : 26, 26, 256 -> 26, 26, 512        \n",
    "        L10 = tf.layers.conv2d(inputs = Y9, filters = 512, kernel_size = [3, 3], strides = (1, 1), padding = \"SAME\")\n",
    "        Y10 = tf.layers.batch_normalization(L10)\n",
    "        Y10 = tf.nn.leaky_relu(Y10, alpha = 0.1)\n",
    "        print(\"L10's shape : \", np.shape(Y10))\n",
    "        \n",
    "        #Layer 11 : 26, 26, 256 -> 26, 26, 512        \n",
    "        L11 = tf.layers.conv2d(inputs = Y10, filters = 256, kernel_size = [3, 3], strides = (1, 1), padding = \"SAME\")\n",
    "        Y11 = tf.layers.batch_normalization(L11)\n",
    "        Y11 = tf.nn.leaky_relu(Y11, alpha = 0.1)\n",
    "        print(\"L11's shape : \", np.shape(Y11))\n",
    "        \n",
    "        #Layer 12 : 26, 26, 256 -> 13, 13, 512        \n",
    "        L12 = tf.layers.conv2d(inputs = Y10, filters = 512, kernel_size = [3, 3], strides = (1, 1), padding = \"SAME\")\n",
    "        Y12 = tf.layers.batch_normalization(L12)\n",
    "        Y12_1 = tf.nn.leaky_relu(Y12, alpha = 0.1)\n",
    "        Y12_2 = tf.layers.max_pooling2d(Y12_1, pool_size = (2, 2), strides = (2, 2))\n",
    "        print(\"L12's shape : \", np.shape(Y12_2))\n",
    "        \n",
    "        #Layer 13 : 13, 13, 512 -> 13, 13, 1024        \n",
    "        L13 = tf.layers.conv2d(inputs = Y12_2, filters = 1024, kernel_size = [3, 3], strides = (1, 1), padding = \"SAME\")\n",
    "        Y13 = tf.layers.batch_normalization(L13)\n",
    "        Y13 = tf.nn.leaky_relu(Y13, alpha = 0.1)\n",
    "        print(\"L13's shape : \", np.shape(Y13))\n",
    "        \n",
    "        #Layer 14 : 13, 13, 1024 -> 13, 13, 512\n",
    "        L14 = tf.layers.conv2d(inputs = Y13, filters = 512, kernel_size = [3, 3], strides = (1, 1), padding = \"SAME\")\n",
    "        Y14 = tf.layers.batch_normalization(L14)\n",
    "        Y14 = tf.nn.leaky_relu(Y14, alpha = 0.1)\n",
    "        print(\"L14's shape : \", np.shape(Y14))\n",
    "        \n",
    "        #Layer 15 : 13, 13, 512 -> 13, 13, 1024        \n",
    "        L15 = tf.layers.conv2d(inputs = Y14, filters = 1024, kernel_size = [3, 3], strides = (1, 1), padding = \"SAME\")\n",
    "        Y15 = tf.layers.batch_normalization(L15)\n",
    "        Y15 = tf.nn.leaky_relu(Y15, alpha = 0.1)\n",
    "        print(\"L15's shape : \", np.shape(Y15))\n",
    "        \n",
    "        #Layer 16 : 13, 13, 1024 -> 13, 13, 512        \n",
    "        L16 = tf.layers.conv2d(inputs = Y15, filters = 512, kernel_size = [3, 3], strides = (1, 1), padding = \"SAME\")\n",
    "        Y16 = tf.layers.batch_normalization(L16)\n",
    "        Y16 = tf.nn.leaky_relu(Y16, alpha = 0.1)\n",
    "        print(\"L16's shape : \", np.shape(Y16))\n",
    "        \n",
    "        #Layer 17 : 13, 13, 512 -> 13, 13, 1024\n",
    "        L17 = tf.layers.conv2d(inputs = Y16, filters = 1024, kernel_size = [3, 3], strides = (1, 1), padding = \"SAME\")\n",
    "        Y17 = tf.layers.batch_normalization(L17)\n",
    "        Y17 = tf.nn.leaky_relu(Y17, alpha = 0.1)\n",
    "        print(\"L17's shape : \", np.shape(Y17))\n",
    "        \n",
    "        #Layer 18 : 13, 13, 1024 -> 13, 13, 1024        \n",
    "        L18 = tf.layers.conv2d(inputs = Y17, filters = 1024, kernel_size = [3, 3], strides = (1, 1), padding = \"SAME\")\n",
    "        Y18 = tf.layers.batch_normalization(L18)\n",
    "        Y18 = tf.nn.leaky_relu(Y18, alpha = 0.1)\n",
    "        print(\"L18's shape : \", np.shape(Y18))\n",
    "        \n",
    "        #Layer 19 : 13, 13, 1024 -> 13, 13, 1024        \n",
    "        L19 = tf.layers.conv2d(inputs = Y18, filters = 1024, kernel_size = [3, 3], strides = (1, 1), padding = \"SAME\")\n",
    "        Y19 = tf.layers.batch_normalization(L19)\n",
    "        Y19 = tf.nn.leaky_relu(Y19, alpha = 0.1)\n",
    "        print(\"L19's shape : \", np.shape(Y19))\n",
    "        \n",
    "        #Layer 20 : 13, 13, 1024 -> 13, 13, 1024+256        \n",
    "        #Layer 12's data loading(논문에선 Layer 13), Y20_1's shape : 13, 13, 256\n",
    "        L20_1 = tf.layers.conv2d(inputs = Y12_1, filters = 64, kernel_size = [3, 3], strides = (1, 1), padding = \"SAME\")\n",
    "        Y20_1 = tf.layers.batch_normalization(L20_1)\n",
    "        Y20_1 = tf.nn.leaky_relu(Y20_1, alpha = 0.1)\n",
    "        Y20_1 = tf.space_to_depth(Y20_1, block_size=2)\n",
    "        print(\"Y20_1's shape : \", np.shape(Y20_1))\n",
    "        Y20_2 = tf.concat([Y20_1, Y19], axis = -1)\n",
    "        print(\"Y20_2's shape : \", np.shape(Y20_2))\n",
    "        \n",
    "        #Layer 21 : 13, 13, 1024+256 -> 13, 13, 1024\n",
    "        L21 = tf.layers.conv2d(inputs = Y20_2, filters = 1024, kernel_size = [3, 3], strides = (1, 1), padding = \"SAME\")\n",
    "        Y21 = tf.layers.batch_normalization(L21)\n",
    "        Y21 = tf.nn.leaky_relu(Y21, alpha = 0.1)\n",
    "        print(\"L21's shape : \", np.shape(Y21))\n",
    "        \n",
    "        #Layer 22 : 13, 13, 1024 -> output layer : 13, 13, output_channel(125)\n",
    "        output_channel = self.num_anchors * (5 + self.num_classes)\n",
    "        logit = tf.layers.conv2d(inputs = Y21, filters = output_channel, kernel_size = [3, 3], strides = (1, 1), padding = \"SAME\")\n",
    "        predict = tf.reshape(logit, [-1, 13, 13, self.num_anchors, 5 + self.num_classes])\n",
    "        print(\"L22's shape : \", np.shape(predict))\n",
    "        return predict#batch, 13, 13, 5, 25(batch, grid_width, grid_height, anchor_box, box_properties + class)\n",
    "    \n",
    "        #predict : batch, 13, 13, 5, 5+1\n",
    "        #label : batch, 13, 13, 5, 6\n",
    "        \n",
    "    def yolo_loss(self, predict, label):\n",
    "        \"\"\"\n",
    "        Build loss function for the model training.\n",
    "        :param kwargs: dict, extra arguments\n",
    "                - loss_weights: list, [xy, wh, resp_confidence, no_resp_confidence, class_probs]\n",
    "        :return tf.Tensor.\n",
    "        \"\"\"\n",
    "\n",
    "        #loss_weights = kwargs.pop('loss_weights', [5, 5, 5, 0.5, 1.0])\n",
    "        # DEBUG\n",
    "        # loss_weights = kwargs.pop('loss_weights', [1.0, 1.0, 1.0, 1.0, 1.0])\n",
    "        grid_h, grid_w = 13, 13\n",
    "        self.pred = predict\n",
    "        self.y = label\n",
    "        num_classes = self.num_classes\n",
    "        anchors = self.anchors\n",
    "        grid_wh = np.reshape([grid_w, grid_h], [\n",
    "                             1, 1, 1, 1, 2]).astype(np.float32)\n",
    "        cxcy = np.transpose([np.tile(np.arange(grid_w), grid_h),\n",
    "                             np.repeat(np.arange(grid_h), grid_w)])\n",
    "        cxcy = np.reshape(cxcy, (1, grid_h, grid_w, 1, 2))\n",
    "\n",
    "        txty, twth = self.pred[..., 0:2], self.pred[..., 2:4]\n",
    "        confidence = tf.sigmoid(self.pred[..., 4:5])\n",
    "        class_probs = tf.nn.softmax(\n",
    "            self.pred[..., 5:], axis=-1) if num_classes > 1 else tf.sigmoid(self.pred[..., 5:])\n",
    "        bxby = tf.sigmoid(txty) + cxcy\n",
    "        pwph = np.reshape(anchors, (1, 1, 1, self.num_anchors, 2)) / 32\n",
    "        bwbh = tf.exp(twth) * pwph\n",
    "\n",
    "        # calculating for prediction\n",
    "        nxny, nwnh = bxby / grid_wh, bwbh / grid_wh\n",
    "        nx1ny1, nx2ny2 = nxny - 0.5 * nwnh, nxny + 0.5 * nwnh\n",
    "        self.pred_y = tf.concat((nx1ny1, nx2ny2, confidence, class_probs), axis=-1)\n",
    "\n",
    "        # calculating IoU for metric\n",
    "        num_objects = tf.reduce_sum(self.y[..., 4:5], axis=[1, 2, 3, 4])\n",
    "        max_nx1ny1 = tf.maximum(self.y[..., 0:2], nx1ny1)\n",
    "        min_nx2ny2 = tf.minimum(self.y[..., 2:4], nx2ny2)\n",
    "        intersect_wh = tf.maximum(min_nx2ny2 - max_nx1ny1, 0.0)\n",
    "        intersect_area = tf.reduce_prod(intersect_wh, axis=-1)\n",
    "        intersect_area = tf.where(\n",
    "            tf.equal(intersect_area, 0.0), tf.zeros_like(intersect_area), intersect_area)\n",
    "        gt_box_area = tf.reduce_prod(\n",
    "            self.y[..., 2:4] - self.y[..., 0:2], axis=-1)\n",
    "        box_area = tf.reduce_prod(nx2ny2 - nx1ny1, axis=-1)\n",
    "        iou = tf.truediv(intersect_area, (gt_box_area + box_area - intersect_area))\n",
    "        sum_iou = tf.reduce_sum(iou, axis=[1, 2, 3])\n",
    "        self.iou = tf.truediv(sum_iou, num_objects)\n",
    "\n",
    "        gt_bxby = 0.5 * (self.y[..., 0:2] + self.y[..., 2:4]) * grid_wh\n",
    "        gt_bwbh = (self.y[..., 2:4] - self.y[..., 0:2]) * grid_wh\n",
    "\n",
    "        resp_mask = self.y[..., 4:5]\n",
    "        no_resp_mask = 1.0 - resp_mask\n",
    "        gt_confidence = resp_mask * tf.expand_dims(iou, axis=-1)\n",
    "        gt_class_probs = self.y[..., 5:]\n",
    "\n",
    "        loss_bxby = 5.0 * resp_mask * tf.square(gt_bxby - bxby)\n",
    "        loss_bwbh = 5.0 * resp_mask * tf.square(tf.sqrt(gt_bwbh) - tf.sqrt(bwbh))\n",
    "        loss_resp_conf = 5.0 * resp_mask * tf.square(gt_confidence - confidence)\n",
    "        loss_no_resp_conf = 0.5 * no_resp_mask * tf.square(gt_confidence - confidence)\n",
    "        loss_class_probs = 1.0 * resp_mask * tf.square(gt_class_probs - class_probs)\n",
    "\n",
    "        merged_loss = tf.concat((loss_bxby,loss_bwbh,loss_resp_conf,loss_no_resp_conf,loss_class_probs), axis=-1)\n",
    "        #self.merged_loss = merged_loss\n",
    "        total_loss = tf.reduce_sum(merged_loss, axis=-1)\n",
    "        total_loss = tf.reduce_mean(total_loss)\n",
    "        return total_loss\n",
    "    \n",
    "#    def model(self):\n",
    "\n",
    "\n",
    "    \n",
    "    def train(self):\n",
    "        #with tf.device('/device:GPU:0'):\n",
    "        batch_image, batch_label = dataset.read_data(self.train_path, image_size=(self.input_image_width, self.input_image_height))\n",
    "        print(np.shape(batch_image))\n",
    "        print(np.shape(batch_label))\n",
    "        #label ; self.label\n",
    "        #network output : y\n",
    "        y = self.network(self.image)\n",
    "        loss = self.yolo_loss(y, self.label)\n",
    "        opt = tf.train.AdamOptimizer(learning_rate=0.00001)\n",
    "        train_step = opt.minimize(loss)\n",
    "        SAVE_PATH = \"./weight/weight.ckpt\"\n",
    "        print(\"1\")\n",
    "        with tf.Session() as sess:\n",
    "            print(\"2\")\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            print(\"3\")\n",
    "            saver = tf.train.Saver()\n",
    "            print(\"4\")\n",
    "            for epoch in range(1):\n",
    "                #print(\"Hello4\")\n",
    "                #image_data, label_data = read_example(TFRECORD_PATH, self.batch_size)\n",
    "                #print(\"Hello5\")\n",
    "                _, loss_data, data = sess.run([train_step, loss, y], feed_dict={self.image: batch_image, self.label: batch_label})\n",
    "\n",
    "                print ('iter: %epoch, loss: %f' % (epoch, loss_data))\n",
    "\n",
    "                if (epoch+1)%5 == 0:\n",
    "                    make_dir(MODEL_PATH)\n",
    "                    saver.save(sess, os.path.join(SAVE_PATH, 'yolo'), global_step=epoch+1)\n",
    "\n",
    "            saver.save(sess, os.path.join(SAVE_PATH,'yolo'), global_step=epoch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2625, 416, 416, 3)\n",
      "(2625, 13, 13, 5, 6)\n",
      "L1's shape :  (?, 208, 208, 32)\n",
      "L2's shape :  (?, 104, 104, 128)\n",
      "L3's shape :  (?, 104, 104, 64)\n",
      "L4's shape :  (?, 52, 52, 128)\n",
      "L5's shape :  (?, 52, 52, 256)\n",
      "L6's shape :  (?, 52, 52, 128)\n",
      "L7's shape :  (?, 26, 26, 256)\n",
      "L8's shape :  (?, 26, 26, 512)\n",
      "L9's shape :  (?, 26, 26, 256)\n",
      "L10's shape :  (?, 26, 26, 512)\n",
      "L11's shape :  (?, 26, 26, 256)\n",
      "L12's shape :  (?, 13, 13, 512)\n",
      "L13's shape :  (?, 13, 13, 1024)\n",
      "L14's shape :  (?, 13, 13, 512)\n",
      "L15's shape :  (?, 13, 13, 1024)\n",
      "L16's shape :  (?, 13, 13, 512)\n",
      "L17's shape :  (?, 13, 13, 1024)\n",
      "L18's shape :  (?, 13, 13, 1024)\n",
      "L19's shape :  (?, 13, 13, 1024)\n",
      "Y20_1's shape :  (?, 13, 13, 256)\n",
      "Y20_2's shape :  (?, 13, 13, 1280)\n",
      "L21's shape :  (?, 13, 13, 1024)\n",
      "L22's shape :  (?, 13, 13, 5, 6)\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device for operation 'save/SaveV2': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\nRegistered kernels:\n  device='CPU'\n\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/device:GPU:0\"](save/Const, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, batch_normalization/beta, batch_normalization/beta/Adam, batch_normalization/beta/Adam_1, batch_normalization/gamma, batch_normalization/gamma/Adam, batch_normalization/gamma/Adam_1, batch_normalization/moving_mean, batch_normalization/moving_variance, batch_normalization_1/beta, batch_normalization_1/beta/Adam, batch_normalization_1/beta/Adam_1, batch_normalization_1/gamma, batch_normalization_1/gamma/Adam, batch_normalization_1/gamma/Adam_1, batch_normalization_1/moving_mean, batch_normalization_1/moving_variance, batch_normalization_10/beta, batch_normalization_10/gamma, batch_normalization_10/moving_mean, batch_normalization_10/moving_variance, batch_normalization_11/beta, batch_normalization_11/beta/Adam, batch_normalization_11/beta/Adam_1, batch_normalization_11/gamma, batch_normalization_11/gamma/Adam, batch_normalization_11/gamma/Adam_1, batch_normalization_11/moving_mean, batch_normalization_11/moving_variance, batch_normalization_12/beta, batch_normalization_12/beta/Adam, batch_normalization_12/beta/Adam_1, batch_normalization_12/gamma, batch_normalization_12/gamma/Adam, batch_normalization_12/gamma/Adam_1, batch_normalization_12/moving_mean, batch_normalization_12/moving_variance, batch_normalization_13/beta, batch_normalization_13/beta/Adam, batch_normalization_13/beta/Adam_1, batch_normalization_13/gamma, batch_normalization_13/gamma/Adam, batch_normalization_13/gamma/Adam_1, batch_normalization_13/moving_mean, batch_normalization_13/moving_variance, batch_normalization_14/beta, batch_normalization_14/beta/Adam, batch_normalization_14/beta/Adam_1, batch_normalization_14/gamma, batch_normalization_14/gamma/Adam, batch_normalization_14/gamma/Adam_1, batch_normalization_14/moving_mean, batch_normalization_14/moving_variance, batch_normalization_15/beta, batch_normalization_15/beta/Adam, batch_normalization_15/beta/Adam_1, batch_normalization_15/gamma, batch_normalization_15/gamma/Adam, batch_normalization_15/gamma/Adam_1, batch_normalization_15/moving_mean, batch_normalization_15/moving_variance, batch_normalization_16/beta, batch_normalization_16/beta/Adam, batch_normalization_16/beta/Adam_1, batch_normalization_16/gamma, batch_normalization_16/gamma/Adam, batch_normalization_16/gamma/Adam_1, batch_normalization_16/moving_mean, batch_normalization_16/moving_variance, batch_normalization_17/beta, batch_normalization_17/beta/Adam, batch_normalization_17/beta/Adam_1, batch_normalization_17/gamma, batch_normalization_17/gamma/Adam, batch_normalization_17/gamma/Adam_1, batch_normalization_17/moving_mean, batch_normalization_17/moving_variance, batch_normalization_18/beta, batch_normalization_18/beta/Adam, batch_normalization_18/beta/Adam_1, batch_normalization_18/gamma, batch_normalization_18/gamma/Adam, batch_normalization_18/gamma/Adam_1, batch_normalization_18/moving_mean, batch_normalization_18/moving_variance, batch_normalization_19/beta, batch_normalization_19/beta/Adam, batch_normalization_19/beta/Adam_1, batch_normalization_19/gamma, batch_normalization_19/gamma/Adam, batch_normalization_19/gamma/Adam_1, batch_normalization_19/moving_mean, batch_normalization_19/moving_variance, batch_normalization_2/beta, batch_normalization_2/beta/Adam, batch_normalization_2/beta/Adam_1, batch_normalization_2/gamma, batch_normalization_2/gamma/Adam, batch_normalization_2/gamma/Adam_1, batch_normalization_2/moving_mean, batch_normalization_2/moving_variance, batch_normalization_20/beta, batch_normalization_20/beta/Adam, batch_normalization_20/beta/Adam_1, batch_normalization_20/gamma, batch_normalization_20/gamma/Adam, batch_normalization_20/gamma/Adam_1, batch_normalization_20/moving_mean, batch_normalization_20/moving_variance, batch_normalization_3/beta, batch_normalization_3/beta/Adam, batch_normalization_3/beta/Adam_1, batch_normalization_3/gamma, batch_normalization_3/gamma/Adam, batch_normalization_3/gamma/Adam_1, batch_normalization_3/moving_mean, batch_normalization_3/moving_variance, batch_normalization_4/beta, batch_normalization_4/beta/Adam, batch_normalization_4/beta/Adam_1, batch_normalization_4/gamma, batch_normalization_4/gamma/Adam, batch_normalization_4/gamma/Adam_1, batch_normalization_4/moving_mean, batch_normalization_4/moving_variance, batch_normalization_5/beta, batch_normalization_5/beta/Adam, batch_normalization_5/beta/Adam_1, batch_normalization_5/gamma, batch_normalization_5/gamma/Adam, batch_normalization_5/gamma/Adam_1, batch_normalization_5/moving_mean, batch_normalization_5/moving_variance, batch_normalization_6/beta, batch_normalization_6/beta/Adam, batch_normalization_6/beta/Adam_1, batch_normalization_6/gamma, batch_normalization_6/gamma/Adam, batch_normalization_6/gamma/Adam_1, batch_normalization_6/moving_mean, batch_normalization_6/moving_variance, batch_normalization_7/beta, batch_normalization_7/beta/Adam, batch_normalization_7/beta/Adam_1, batch_normalization_7/gamma, batch_normalization_7/gamma/Adam, batch_normalization_7/gamma/Adam_1, batch_normalization_7/moving_mean, batch_normalization_7/moving_variance, batch_normalization_8/beta, batch_normalization_8/beta/Adam, batch_normalization_8/beta/Adam_1, batch_normalization_8/gamma, batch_normalization_8/gamma/Adam, batch_normalization_8/gamma/Adam_1, batch_normalization_8/moving_mean, batch_normalization_8/moving_variance, batch_normalization_9/beta, batch_normalization_9/beta/Adam, batch_normalization_9/beta/Adam_1, batch_normalization_9/gamma, batch_normalization_9/gamma/Adam, batch_normalization_9/gamma/Adam_1, batch_normalization_9/moving_mean, batch_normalization_9/moving_variance, beta1_power, beta2_power, conv2d/bias, conv2d/bias/Adam, conv2d/bias/Adam_1, conv2d/kernel, conv2d/kernel/Adam, conv2d/kernel/Adam_1, conv2d_1/bias, conv2d_1/bias/Adam, conv2d_1/bias/Adam_1, conv2d_1/kernel, conv2d_1/kernel/Adam, conv2d_1/kernel/Adam_1, conv2d_10/bias, conv2d_10/kernel, conv2d_11/bias, conv2d_11/bias/Adam, conv2d_11/bias/Adam_1, conv2d_11/kernel, conv2d_11/kernel/Adam, conv2d_11/kernel/Adam_1, conv2d_12/bias, conv2d_12/bias/Adam, conv2d_12/bias/Adam_1, conv2d_12/kernel, conv2d_12/kernel/Adam, conv2d_12/kernel/Adam_1, conv2d_13/bias, conv2d_13/bias/Adam, conv2d_13/bias/Adam_1, conv2d_13/kernel, conv2d_13/kernel/Adam, conv2d_13/kernel/Adam_1, conv2d_14/bias, conv2d_14/bias/Adam, conv2d_14/bias/Adam_1, conv2d_14/kernel, conv2d_14/kernel/Adam, conv2d_14/kernel/Adam_1, conv2d_15/bias, conv2d_15/bias/Adam, conv2d_15/bias/Adam_1, conv2d_15/kernel, conv2d_15/kernel/Adam, conv2d_15/kernel/Adam_1, conv2d_16/bias, conv2d_16/bias/Adam, conv2d_16/bias/Adam_1, conv2d_16/kernel, conv2d_16/kernel/Adam, conv2d_16/kernel/Adam_1, conv2d_17/bias, conv2d_17/bias/Adam, conv2d_17/bias/Adam_1, conv2d_17/kernel, conv2d_17/kernel/Adam, conv2d_17/kernel/Adam_1, conv2d_18/bias, conv2d_18/bias/Adam, conv2d_18/bias/Adam_1, conv2d_18/kernel, conv2d_18/kernel/Adam, conv2d_18/kernel/Adam_1, conv2d_19/bias, conv2d_19/bias/Adam, conv2d_19/bias/Adam_1, conv2d_19/kernel, conv2d_19/kernel/Adam, conv2d_19/kernel/Adam_1, conv2d_2/bias, conv2d_2/bias/Adam, conv2d_2/bias/Adam_1, conv2d_2/kernel, conv2d_2/kernel/Adam, conv2d_2/kernel/Adam_1, conv2d_20/bias, conv2d_20/bias/Adam, conv2d_20/bias/Adam_1, conv2d_20/kernel, conv2d_20/kernel/Adam, conv2d_20/kernel/Adam_1, conv2d_21/bias, conv2d_21/bias/Adam, conv2d_21/bias/Adam_1, conv2d_21/kernel, conv2d_21/kernel/Adam, conv2d_21/kernel/Adam_1, conv2d_3/bias, conv2d_3/bias/Adam, conv2d_3/bias/Adam_1, conv2d_3/kernel, conv2d_3/kernel/Adam, conv2d_3/kernel/Adam_1, conv2d_4/bias, conv2d_4/bias/Adam, conv2d_4/bias/Adam_1, conv2d_4/kernel, conv2d_4/kernel/Adam, conv2d_4/kernel/Adam_1, conv2d_5/bias, conv2d_5/bias/Adam, conv2d_5/bias/Adam_1, conv2d_5/kernel, conv2d_5/kernel/Adam, conv2d_5/kernel/Adam_1, conv2d_6/bias, conv2d_6/bias/Adam, conv2d_6/bias/Adam_1, conv2d_6/kernel, conv2d_6/kernel/Adam, conv2d_6/kernel/Adam_1, conv2d_7/bias, conv2d_7/bias/Adam, conv2d_7/bias/Adam_1, conv2d_7/kernel, conv2d_7/kernel/Adam, conv2d_7/kernel/Adam_1, conv2d_8/bias, conv2d_8/bias/Adam, conv2d_8/bias/Adam_1, conv2d_8/kernel, conv2d_8/kernel/Adam, conv2d_8/kernel/Adam_1, conv2d_9/bias, conv2d_9/bias/Adam, conv2d_9/bias/Adam_1, conv2d_9/kernel, conv2d_9/kernel/Adam, conv2d_9/kernel/Adam_1)]]\n\nCaused by op 'save/SaveV2', defined at:\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-388a246ecaff>\", line 2, in <module>\n    yolo_object.train()\n  File \"<ipython-input-2-37f96ed824a0>\", line 258, in train\n    saver = tf.train.Saver()\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1338, in __init__\n    self.build()\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1347, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1384, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 832, in _build_internal\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 350, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 266, in save_op\n    tensors)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1800, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'save/SaveV2': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\nRegistered kernels:\n  device='CPU'\n\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/device:GPU:0\"](save/Const, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, batch_normalization/beta, batch_normalization/beta/Adam, batch_normalization/beta/Adam_1, batch_normalization/gamma, batch_normalization/gamma/Adam, batch_normalization/gamma/Adam_1, batch_normalization/moving_mean, batch_normalization/moving_variance, batch_normalization_1/beta, batch_normalization_1/beta/Adam, batch_normalization_1/beta/Adam_1, batch_normalization_1/gamma, batch_normalization_1/gamma/Adam, batch_normalization_1/gamma/Adam_1, batch_normalization_1/moving_mean, batch_normalization_1/moving_variance, batch_normalization_10/beta, batch_normalization_10/gamma, batch_normalization_10/moving_mean, batch_normalization_10/moving_variance, batch_normalization_11/beta, batch_normalization_11/beta/Adam, batch_normalization_11/beta/Adam_1, batch_normalization_11/gamma, batch_normalization_11/gamma/Adam, batch_normalization_11/gamma/Adam_1, batch_normalization_11/moving_mean, batch_normalization_11/moving_variance, batch_normalization_12/beta, batch_normalization_12/beta/Adam, batch_normalization_12/beta/Adam_1, batch_normalization_12/gamma, batch_normalization_12/gamma/Adam, batch_normalization_12/gamma/Adam_1, batch_normalization_12/moving_mean, batch_normalization_12/moving_variance, batch_normalization_13/beta, batch_normalization_13/beta/Adam, batch_normalization_13/beta/Adam_1, batch_normalization_13/gamma, batch_normalization_13/gamma/Adam, batch_normalization_13/gamma/Adam_1, batch_normalization_13/moving_mean, batch_normalization_13/moving_variance, batch_normalization_14/beta, batch_normalization_14/beta/Adam, batch_normalization_14/beta/Adam_1, batch_normalization_14/gamma, batch_normalization_14/gamma/Adam, batch_normalization_14/gamma/Adam_1, batch_normalization_14/moving_mean, batch_normalization_14/moving_variance, batch_normalization_15/beta, batch_normalization_15/beta/Adam, batch_normalization_15/beta/Adam_1, batch_normalization_15/gamma, batch_normalization_15/gamma/Adam, batch_normalization_15/gamma/Adam_1, batch_normalization_15/moving_mean, batch_normalization_15/moving_variance, batch_normalization_16/beta, batch_normalization_16/beta/Adam, batch_normalization_16/beta/Adam_1, batch_normalization_16/gamma, batch_normalization_16/gamma/Adam, batch_normalization_16/gamma/Adam_1, batch_normalization_16/moving_mean, batch_normalization_16/moving_variance, batch_normalization_17/beta, batch_normalization_17/beta/Adam, batch_normalization_17/beta/Adam_1, batch_normalization_17/gamma, batch_normalization_17/gamma/Adam, batch_normalization_17/gamma/Adam_1, batch_normalization_17/moving_mean, batch_normalization_17/moving_variance, batch_normalization_18/beta, batch_normalization_18/beta/Adam, batch_normalization_18/beta/Adam_1, batch_normalization_18/gamma, batch_normalization_18/gamma/Adam, batch_normalization_18/gamma/Adam_1, batch_normalization_18/moving_mean, batch_normalization_18/moving_variance, batch_normalization_19/beta, batch_normalization_19/beta/Adam, batch_normalization_19/beta/Adam_1, batch_normalization_19/gamma, batch_normalization_19/gamma/Adam, batch_normalization_19/gamma/Adam_1, batch_normalization_19/moving_mean, batch_normalization_19/moving_variance, batch_normalization_2/beta, batch_normalization_2/beta/Adam, batch_normalization_2/beta/Adam_1, batch_normalization_2/gamma, batch_normalization_2/gamma/Adam, batch_normalization_2/gamma/Adam_1, batch_normalization_2/moving_mean, batch_normalization_2/moving_variance, batch_normalization_20/beta, batch_normalization_20/beta/Adam, batch_normalization_20/beta/Adam_1, batch_normalization_20/gamma, batch_normalization_20/gamma/Adam, batch_normalization_20/gamma/Adam_1, batch_normalization_20/moving_mean, batch_normalization_20/moving_variance, batch_normalization_3/beta, batch_normalization_3/beta/Adam, batch_normalization_3/beta/Adam_1, batch_normalization_3/gamma, batch_normalization_3/gamma/Adam, batch_normalization_3/gamma/Adam_1, batch_normalization_3/moving_mean, batch_normalization_3/moving_variance, batch_normalization_4/beta, batch_normalization_4/beta/Adam, batch_normalization_4/beta/Adam_1, batch_normalization_4/gamma, batch_normalization_4/gamma/Adam, batch_normalization_4/gamma/Adam_1, batch_normalization_4/moving_mean, batch_normalization_4/moving_variance, batch_normalization_5/beta, batch_normalization_5/beta/Adam, batch_normalization_5/beta/Adam_1, batch_normalization_5/gamma, batch_normalization_5/gamma/Adam, batch_normalization_5/gamma/Adam_1, batch_normalization_5/moving_mean, batch_normalization_5/moving_variance, batch_normalization_6/beta, batch_normalization_6/beta/Adam, batch_normalization_6/beta/Adam_1, batch_normalization_6/gamma, batch_normalization_6/gamma/Adam, batch_normalization_6/gamma/Adam_1, batch_normalization_6/moving_mean, batch_normalization_6/moving_variance, batch_normalization_7/beta, batch_normalization_7/beta/Adam, batch_normalization_7/beta/Adam_1, batch_normalization_7/gamma, batch_normalization_7/gamma/Adam, batch_normalization_7/gamma/Adam_1, batch_normalization_7/moving_mean, batch_normalization_7/moving_variance, batch_normalization_8/beta, batch_normalization_8/beta/Adam, batch_normalization_8/beta/Adam_1, batch_normalization_8/gamma, batch_normalization_8/gamma/Adam, batch_normalization_8/gamma/Adam_1, batch_normalization_8/moving_mean, batch_normalization_8/moving_variance, batch_normalization_9/beta, batch_normalization_9/beta/Adam, batch_normalization_9/beta/Adam_1, batch_normalization_9/gamma, batch_normalization_9/gamma/Adam, batch_normalization_9/gamma/Adam_1, batch_normalization_9/moving_mean, batch_normalization_9/moving_variance, beta1_power, beta2_power, conv2d/bias, conv2d/bias/Adam, conv2d/bias/Adam_1, conv2d/kernel, conv2d/kernel/Adam, conv2d/kernel/Adam_1, conv2d_1/bias, conv2d_1/bias/Adam, conv2d_1/bias/Adam_1, conv2d_1/kernel, conv2d_1/kernel/Adam, conv2d_1/kernel/Adam_1, conv2d_10/bias, conv2d_10/kernel, conv2d_11/bias, conv2d_11/bias/Adam, conv2d_11/bias/Adam_1, conv2d_11/kernel, conv2d_11/kernel/Adam, conv2d_11/kernel/Adam_1, conv2d_12/bias, conv2d_12/bias/Adam, conv2d_12/bias/Adam_1, conv2d_12/kernel, conv2d_12/kernel/Adam, conv2d_12/kernel/Adam_1, conv2d_13/bias, conv2d_13/bias/Adam, conv2d_13/bias/Adam_1, conv2d_13/kernel, conv2d_13/kernel/Adam, conv2d_13/kernel/Adam_1, conv2d_14/bias, conv2d_14/bias/Adam, conv2d_14/bias/Adam_1, conv2d_14/kernel, conv2d_14/kernel/Adam, conv2d_14/kernel/Adam_1, conv2d_15/bias, conv2d_15/bias/Adam, conv2d_15/bias/Adam_1, conv2d_15/kernel, conv2d_15/kernel/Adam, conv2d_15/kernel/Adam_1, conv2d_16/bias, conv2d_16/bias/Adam, conv2d_16/bias/Adam_1, conv2d_16/kernel, conv2d_16/kernel/Adam, conv2d_16/kernel/Adam_1, conv2d_17/bias, conv2d_17/bias/Adam, conv2d_17/bias/Adam_1, conv2d_17/kernel, conv2d_17/kernel/Adam, conv2d_17/kernel/Adam_1, conv2d_18/bias, conv2d_18/bias/Adam, conv2d_18/bias/Adam_1, conv2d_18/kernel, conv2d_18/kernel/Adam, conv2d_18/kernel/Adam_1, conv2d_19/bias, conv2d_19/bias/Adam, conv2d_19/bias/Adam_1, conv2d_19/kernel, conv2d_19/kernel/Adam, conv2d_19/kernel/Adam_1, conv2d_2/bias, conv2d_2/bias/Adam, conv2d_2/bias/Adam_1, conv2d_2/kernel, conv2d_2/kernel/Adam, conv2d_2/kernel/Adam_1, conv2d_20/bias, conv2d_20/bias/Adam, conv2d_20/bias/Adam_1, conv2d_20/kernel, conv2d_20/kernel/Adam, conv2d_20/kernel/Adam_1, conv2d_21/bias, conv2d_21/bias/Adam, conv2d_21/bias/Adam_1, conv2d_21/kernel, conv2d_21/kernel/Adam, conv2d_21/kernel/Adam_1, conv2d_3/bias, conv2d_3/bias/Adam, conv2d_3/bias/Adam_1, conv2d_3/kernel, conv2d_3/kernel/Adam, conv2d_3/kernel/Adam_1, conv2d_4/bias, conv2d_4/bias/Adam, conv2d_4/bias/Adam_1, conv2d_4/kernel, conv2d_4/kernel/Adam, conv2d_4/kernel/Adam_1, conv2d_5/bias, conv2d_5/bias/Adam, conv2d_5/bias/Adam_1, conv2d_5/kernel, conv2d_5/kernel/Adam, conv2d_5/kernel/Adam_1, conv2d_6/bias, conv2d_6/bias/Adam, conv2d_6/bias/Adam_1, conv2d_6/kernel, conv2d_6/kernel/Adam, conv2d_6/kernel/Adam_1, conv2d_7/bias, conv2d_7/bias/Adam, conv2d_7/bias/Adam_1, conv2d_7/kernel, conv2d_7/kernel/Adam, conv2d_7/kernel/Adam_1, conv2d_8/bias, conv2d_8/bias/Adam, conv2d_8/bias/Adam_1, conv2d_8/kernel, conv2d_8/kernel/Adam, conv2d_8/kernel/Adam_1, conv2d_9/bias, conv2d_9/bias/Adam, conv2d_9/bias/Adam_1, conv2d_9/kernel, conv2d_9/kernel/Adam, conv2d_9/kernel/Adam_1)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1305\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1339\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1340\u001b[1;33m         \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1341\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation 'save/SaveV2': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\nRegistered kernels:\n  device='CPU'\n\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/device:GPU:0\"](save/Const, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, batch_normalization/beta, batch_normalization/beta/Adam, batch_normalization/beta/Adam_1, batch_normalization/gamma, batch_normalization/gamma/Adam, batch_normalization/gamma/Adam_1, batch_normalization/moving_mean, batch_normalization/moving_variance, batch_normalization_1/beta, batch_normalization_1/beta/Adam, batch_normalization_1/beta/Adam_1, batch_normalization_1/gamma, batch_normalization_1/gamma/Adam, batch_normalization_1/gamma/Adam_1, batch_normalization_1/moving_mean, batch_normalization_1/moving_variance, batch_normalization_10/beta, batch_normalization_10/gamma, batch_normalization_10/moving_mean, batch_normalization_10/moving_variance, batch_normalization_11/beta, batch_normalization_11/beta/Adam, batch_normalization_11/beta/Adam_1, batch_normalization_11/gamma, batch_normalization_11/gamma/Adam, batch_normalization_11/gamma/Adam_1, batch_normalization_11/moving_mean, batch_normalization_11/moving_variance, batch_normalization_12/beta, batch_normalization_12/beta/Adam, batch_normalization_12/beta/Adam_1, batch_normalization_12/gamma, batch_normalization_12/gamma/Adam, batch_normalization_12/gamma/Adam_1, batch_normalization_12/moving_mean, batch_normalization_12/moving_variance, batch_normalization_13/beta, batch_normalization_13/beta/Adam, batch_normalization_13/beta/Adam_1, batch_normalization_13/gamma, batch_normalization_13/gamma/Adam, batch_normalization_13/gamma/Adam_1, batch_normalization_13/moving_mean, batch_normalization_13/moving_variance, batch_normalization_14/beta, batch_normalization_14/beta/Adam, batch_normalization_14/beta/Adam_1, batch_normalization_14/gamma, batch_normalization_14/gamma/Adam, batch_normalization_14/gamma/Adam_1, batch_normalization_14/moving_mean, batch_normalization_14/moving_variance, batch_normalization_15/beta, batch_normalization_15/beta/Adam, batch_normalization_15/beta/Adam_1, batch_normalization_15/gamma, batch_normalization_15/gamma/Adam, batch_normalization_15/gamma/Adam_1, batch_normalization_15/moving_mean, batch_normalization_15/moving_variance, batch_normalization_16/beta, batch_normalization_16/beta/Adam, batch_normalization_16/beta/Adam_1, batch_normalization_16/gamma, batch_normalization_16/gamma/Adam, batch_normalization_16/gamma/Adam_1, batch_normalization_16/moving_mean, batch_normalization_16/moving_variance, batch_normalization_17/beta, batch_normalization_17/beta/Adam, batch_normalization_17/beta/Adam_1, batch_normalization_17/gamma, batch_normalization_17/gamma/Adam, batch_normalization_17/gamma/Adam_1, batch_normalization_17/moving_mean, batch_normalization_17/moving_variance, batch_normalization_18/beta, batch_normalization_18/beta/Adam, batch_normalization_18/beta/Adam_1, batch_normalization_18/gamma, batch_normalization_18/gamma/Adam, batch_normalization_18/gamma/Adam_1, batch_normalization_18/moving_mean, batch_normalization_18/moving_variance, batch_normalization_19/beta, batch_normalization_19/beta/Adam, batch_normalization_19/beta/Adam_1, batch_normalization_19/gamma, batch_normalization_19/gamma/Adam, batch_normalization_19/gamma/Adam_1, batch_normalization_19/moving_mean, batch_normalization_19/moving_variance, batch_normalization_2/beta, batch_normalization_2/beta/Adam, batch_normalization_2/beta/Adam_1, batch_normalization_2/gamma, batch_normalization_2/gamma/Adam, batch_normalization_2/gamma/Adam_1, batch_normalization_2/moving_mean, batch_normalization_2/moving_variance, batch_normalization_20/beta, batch_normalization_20/beta/Adam, batch_normalization_20/beta/Adam_1, batch_normalization_20/gamma, batch_normalization_20/gamma/Adam, batch_normalization_20/gamma/Adam_1, batch_normalization_20/moving_mean, batch_normalization_20/moving_variance, batch_normalization_3/beta, batch_normalization_3/beta/Adam, batch_normalization_3/beta/Adam_1, batch_normalization_3/gamma, batch_normalization_3/gamma/Adam, batch_normalization_3/gamma/Adam_1, batch_normalization_3/moving_mean, batch_normalization_3/moving_variance, batch_normalization_4/beta, batch_normalization_4/beta/Adam, batch_normalization_4/beta/Adam_1, batch_normalization_4/gamma, batch_normalization_4/gamma/Adam, batch_normalization_4/gamma/Adam_1, batch_normalization_4/moving_mean, batch_normalization_4/moving_variance, batch_normalization_5/beta, batch_normalization_5/beta/Adam, batch_normalization_5/beta/Adam_1, batch_normalization_5/gamma, batch_normalization_5/gamma/Adam, batch_normalization_5/gamma/Adam_1, batch_normalization_5/moving_mean, batch_normalization_5/moving_variance, batch_normalization_6/beta, batch_normalization_6/beta/Adam, batch_normalization_6/beta/Adam_1, batch_normalization_6/gamma, batch_normalization_6/gamma/Adam, batch_normalization_6/gamma/Adam_1, batch_normalization_6/moving_mean, batch_normalization_6/moving_variance, batch_normalization_7/beta, batch_normalization_7/beta/Adam, batch_normalization_7/beta/Adam_1, batch_normalization_7/gamma, batch_normalization_7/gamma/Adam, batch_normalization_7/gamma/Adam_1, batch_normalization_7/moving_mean, batch_normalization_7/moving_variance, batch_normalization_8/beta, batch_normalization_8/beta/Adam, batch_normalization_8/beta/Adam_1, batch_normalization_8/gamma, batch_normalization_8/gamma/Adam, batch_normalization_8/gamma/Adam_1, batch_normalization_8/moving_mean, batch_normalization_8/moving_variance, batch_normalization_9/beta, batch_normalization_9/beta/Adam, batch_normalization_9/beta/Adam_1, batch_normalization_9/gamma, batch_normalization_9/gamma/Adam, batch_normalization_9/gamma/Adam_1, batch_normalization_9/moving_mean, batch_normalization_9/moving_variance, beta1_power, beta2_power, conv2d/bias, conv2d/bias/Adam, conv2d/bias/Adam_1, conv2d/kernel, conv2d/kernel/Adam, conv2d/kernel/Adam_1, conv2d_1/bias, conv2d_1/bias/Adam, conv2d_1/bias/Adam_1, conv2d_1/kernel, conv2d_1/kernel/Adam, conv2d_1/kernel/Adam_1, conv2d_10/bias, conv2d_10/kernel, conv2d_11/bias, conv2d_11/bias/Adam, conv2d_11/bias/Adam_1, conv2d_11/kernel, conv2d_11/kernel/Adam, conv2d_11/kernel/Adam_1, conv2d_12/bias, conv2d_12/bias/Adam, conv2d_12/bias/Adam_1, conv2d_12/kernel, conv2d_12/kernel/Adam, conv2d_12/kernel/Adam_1, conv2d_13/bias, conv2d_13/bias/Adam, conv2d_13/bias/Adam_1, conv2d_13/kernel, conv2d_13/kernel/Adam, conv2d_13/kernel/Adam_1, conv2d_14/bias, conv2d_14/bias/Adam, conv2d_14/bias/Adam_1, conv2d_14/kernel, conv2d_14/kernel/Adam, conv2d_14/kernel/Adam_1, conv2d_15/bias, conv2d_15/bias/Adam, conv2d_15/bias/Adam_1, conv2d_15/kernel, conv2d_15/kernel/Adam, conv2d_15/kernel/Adam_1, conv2d_16/bias, conv2d_16/bias/Adam, conv2d_16/bias/Adam_1, conv2d_16/kernel, conv2d_16/kernel/Adam, conv2d_16/kernel/Adam_1, conv2d_17/bias, conv2d_17/bias/Adam, conv2d_17/bias/Adam_1, conv2d_17/kernel, conv2d_17/kernel/Adam, conv2d_17/kernel/Adam_1, conv2d_18/bias, conv2d_18/bias/Adam, conv2d_18/bias/Adam_1, conv2d_18/kernel, conv2d_18/kernel/Adam, conv2d_18/kernel/Adam_1, conv2d_19/bias, conv2d_19/bias/Adam, conv2d_19/bias/Adam_1, conv2d_19/kernel, conv2d_19/kernel/Adam, conv2d_19/kernel/Adam_1, conv2d_2/bias, conv2d_2/bias/Adam, conv2d_2/bias/Adam_1, conv2d_2/kernel, conv2d_2/kernel/Adam, conv2d_2/kernel/Adam_1, conv2d_20/bias, conv2d_20/bias/Adam, conv2d_20/bias/Adam_1, conv2d_20/kernel, conv2d_20/kernel/Adam, conv2d_20/kernel/Adam_1, conv2d_21/bias, conv2d_21/bias/Adam, conv2d_21/bias/Adam_1, conv2d_21/kernel, conv2d_21/kernel/Adam, conv2d_21/kernel/Adam_1, conv2d_3/bias, conv2d_3/bias/Adam, conv2d_3/bias/Adam_1, conv2d_3/kernel, conv2d_3/kernel/Adam, conv2d_3/kernel/Adam_1, conv2d_4/bias, conv2d_4/bias/Adam, conv2d_4/bias/Adam_1, conv2d_4/kernel, conv2d_4/kernel/Adam, conv2d_4/kernel/Adam_1, conv2d_5/bias, conv2d_5/bias/Adam, conv2d_5/bias/Adam_1, conv2d_5/kernel, conv2d_5/kernel/Adam, conv2d_5/kernel/Adam_1, conv2d_6/bias, conv2d_6/bias/Adam, conv2d_6/bias/Adam_1, conv2d_6/kernel, conv2d_6/kernel/Adam, conv2d_6/kernel/Adam_1, conv2d_7/bias, conv2d_7/bias/Adam, conv2d_7/bias/Adam_1, conv2d_7/kernel, conv2d_7/kernel/Adam, conv2d_7/kernel/Adam_1, conv2d_8/bias, conv2d_8/bias/Adam, conv2d_8/bias/Adam_1, conv2d_8/kernel, conv2d_8/kernel/Adam, conv2d_8/kernel/Adam_1, conv2d_9/bias, conv2d_9/bias/Adam, conv2d_9/bias/Adam_1, conv2d_9/kernel, conv2d_9/kernel/Adam, conv2d_9/kernel/Adam_1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-86128a34bd6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0myolo_object\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0myolo_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-c30e621b1a91>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"3\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation 'save/SaveV2': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\nRegistered kernels:\n  device='CPU'\n\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/device:GPU:0\"](save/Const, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, batch_normalization/beta, batch_normalization/beta/Adam, batch_normalization/beta/Adam_1, batch_normalization/gamma, batch_normalization/gamma/Adam, batch_normalization/gamma/Adam_1, batch_normalization/moving_mean, batch_normalization/moving_variance, batch_normalization_1/beta, batch_normalization_1/beta/Adam, batch_normalization_1/beta/Adam_1, batch_normalization_1/gamma, batch_normalization_1/gamma/Adam, batch_normalization_1/gamma/Adam_1, batch_normalization_1/moving_mean, batch_normalization_1/moving_variance, batch_normalization_10/beta, batch_normalization_10/gamma, batch_normalization_10/moving_mean, batch_normalization_10/moving_variance, batch_normalization_11/beta, batch_normalization_11/beta/Adam, batch_normalization_11/beta/Adam_1, batch_normalization_11/gamma, batch_normalization_11/gamma/Adam, batch_normalization_11/gamma/Adam_1, batch_normalization_11/moving_mean, batch_normalization_11/moving_variance, batch_normalization_12/beta, batch_normalization_12/beta/Adam, batch_normalization_12/beta/Adam_1, batch_normalization_12/gamma, batch_normalization_12/gamma/Adam, batch_normalization_12/gamma/Adam_1, batch_normalization_12/moving_mean, batch_normalization_12/moving_variance, batch_normalization_13/beta, batch_normalization_13/beta/Adam, batch_normalization_13/beta/Adam_1, batch_normalization_13/gamma, batch_normalization_13/gamma/Adam, batch_normalization_13/gamma/Adam_1, batch_normalization_13/moving_mean, batch_normalization_13/moving_variance, batch_normalization_14/beta, batch_normalization_14/beta/Adam, batch_normalization_14/beta/Adam_1, batch_normalization_14/gamma, batch_normalization_14/gamma/Adam, batch_normalization_14/gamma/Adam_1, batch_normalization_14/moving_mean, batch_normalization_14/moving_variance, batch_normalization_15/beta, batch_normalization_15/beta/Adam, batch_normalization_15/beta/Adam_1, batch_normalization_15/gamma, batch_normalization_15/gamma/Adam, batch_normalization_15/gamma/Adam_1, batch_normalization_15/moving_mean, batch_normalization_15/moving_variance, batch_normalization_16/beta, batch_normalization_16/beta/Adam, batch_normalization_16/beta/Adam_1, batch_normalization_16/gamma, batch_normalization_16/gamma/Adam, batch_normalization_16/gamma/Adam_1, batch_normalization_16/moving_mean, batch_normalization_16/moving_variance, batch_normalization_17/beta, batch_normalization_17/beta/Adam, batch_normalization_17/beta/Adam_1, batch_normalization_17/gamma, batch_normalization_17/gamma/Adam, batch_normalization_17/gamma/Adam_1, batch_normalization_17/moving_mean, batch_normalization_17/moving_variance, batch_normalization_18/beta, batch_normalization_18/beta/Adam, batch_normalization_18/beta/Adam_1, batch_normalization_18/gamma, batch_normalization_18/gamma/Adam, batch_normalization_18/gamma/Adam_1, batch_normalization_18/moving_mean, batch_normalization_18/moving_variance, batch_normalization_19/beta, batch_normalization_19/beta/Adam, batch_normalization_19/beta/Adam_1, batch_normalization_19/gamma, batch_normalization_19/gamma/Adam, batch_normalization_19/gamma/Adam_1, batch_normalization_19/moving_mean, batch_normalization_19/moving_variance, batch_normalization_2/beta, batch_normalization_2/beta/Adam, batch_normalization_2/beta/Adam_1, batch_normalization_2/gamma, batch_normalization_2/gamma/Adam, batch_normalization_2/gamma/Adam_1, batch_normalization_2/moving_mean, batch_normalization_2/moving_variance, batch_normalization_20/beta, batch_normalization_20/beta/Adam, batch_normalization_20/beta/Adam_1, batch_normalization_20/gamma, batch_normalization_20/gamma/Adam, batch_normalization_20/gamma/Adam_1, batch_normalization_20/moving_mean, batch_normalization_20/moving_variance, batch_normalization_3/beta, batch_normalization_3/beta/Adam, batch_normalization_3/beta/Adam_1, batch_normalization_3/gamma, batch_normalization_3/gamma/Adam, batch_normalization_3/gamma/Adam_1, batch_normalization_3/moving_mean, batch_normalization_3/moving_variance, batch_normalization_4/beta, batch_normalization_4/beta/Adam, batch_normalization_4/beta/Adam_1, batch_normalization_4/gamma, batch_normalization_4/gamma/Adam, batch_normalization_4/gamma/Adam_1, batch_normalization_4/moving_mean, batch_normalization_4/moving_variance, batch_normalization_5/beta, batch_normalization_5/beta/Adam, batch_normalization_5/beta/Adam_1, batch_normalization_5/gamma, batch_normalization_5/gamma/Adam, batch_normalization_5/gamma/Adam_1, batch_normalization_5/moving_mean, batch_normalization_5/moving_variance, batch_normalization_6/beta, batch_normalization_6/beta/Adam, batch_normalization_6/beta/Adam_1, batch_normalization_6/gamma, batch_normalization_6/gamma/Adam, batch_normalization_6/gamma/Adam_1, batch_normalization_6/moving_mean, batch_normalization_6/moving_variance, batch_normalization_7/beta, batch_normalization_7/beta/Adam, batch_normalization_7/beta/Adam_1, batch_normalization_7/gamma, batch_normalization_7/gamma/Adam, batch_normalization_7/gamma/Adam_1, batch_normalization_7/moving_mean, batch_normalization_7/moving_variance, batch_normalization_8/beta, batch_normalization_8/beta/Adam, batch_normalization_8/beta/Adam_1, batch_normalization_8/gamma, batch_normalization_8/gamma/Adam, batch_normalization_8/gamma/Adam_1, batch_normalization_8/moving_mean, batch_normalization_8/moving_variance, batch_normalization_9/beta, batch_normalization_9/beta/Adam, batch_normalization_9/beta/Adam_1, batch_normalization_9/gamma, batch_normalization_9/gamma/Adam, batch_normalization_9/gamma/Adam_1, batch_normalization_9/moving_mean, batch_normalization_9/moving_variance, beta1_power, beta2_power, conv2d/bias, conv2d/bias/Adam, conv2d/bias/Adam_1, conv2d/kernel, conv2d/kernel/Adam, conv2d/kernel/Adam_1, conv2d_1/bias, conv2d_1/bias/Adam, conv2d_1/bias/Adam_1, conv2d_1/kernel, conv2d_1/kernel/Adam, conv2d_1/kernel/Adam_1, conv2d_10/bias, conv2d_10/kernel, conv2d_11/bias, conv2d_11/bias/Adam, conv2d_11/bias/Adam_1, conv2d_11/kernel, conv2d_11/kernel/Adam, conv2d_11/kernel/Adam_1, conv2d_12/bias, conv2d_12/bias/Adam, conv2d_12/bias/Adam_1, conv2d_12/kernel, conv2d_12/kernel/Adam, conv2d_12/kernel/Adam_1, conv2d_13/bias, conv2d_13/bias/Adam, conv2d_13/bias/Adam_1, conv2d_13/kernel, conv2d_13/kernel/Adam, conv2d_13/kernel/Adam_1, conv2d_14/bias, conv2d_14/bias/Adam, conv2d_14/bias/Adam_1, conv2d_14/kernel, conv2d_14/kernel/Adam, conv2d_14/kernel/Adam_1, conv2d_15/bias, conv2d_15/bias/Adam, conv2d_15/bias/Adam_1, conv2d_15/kernel, conv2d_15/kernel/Adam, conv2d_15/kernel/Adam_1, conv2d_16/bias, conv2d_16/bias/Adam, conv2d_16/bias/Adam_1, conv2d_16/kernel, conv2d_16/kernel/Adam, conv2d_16/kernel/Adam_1, conv2d_17/bias, conv2d_17/bias/Adam, conv2d_17/bias/Adam_1, conv2d_17/kernel, conv2d_17/kernel/Adam, conv2d_17/kernel/Adam_1, conv2d_18/bias, conv2d_18/bias/Adam, conv2d_18/bias/Adam_1, conv2d_18/kernel, conv2d_18/kernel/Adam, conv2d_18/kernel/Adam_1, conv2d_19/bias, conv2d_19/bias/Adam, conv2d_19/bias/Adam_1, conv2d_19/kernel, conv2d_19/kernel/Adam, conv2d_19/kernel/Adam_1, conv2d_2/bias, conv2d_2/bias/Adam, conv2d_2/bias/Adam_1, conv2d_2/kernel, conv2d_2/kernel/Adam, conv2d_2/kernel/Adam_1, conv2d_20/bias, conv2d_20/bias/Adam, conv2d_20/bias/Adam_1, conv2d_20/kernel, conv2d_20/kernel/Adam, conv2d_20/kernel/Adam_1, conv2d_21/bias, conv2d_21/bias/Adam, conv2d_21/bias/Adam_1, conv2d_21/kernel, conv2d_21/kernel/Adam, conv2d_21/kernel/Adam_1, conv2d_3/bias, conv2d_3/bias/Adam, conv2d_3/bias/Adam_1, conv2d_3/kernel, conv2d_3/kernel/Adam, conv2d_3/kernel/Adam_1, conv2d_4/bias, conv2d_4/bias/Adam, conv2d_4/bias/Adam_1, conv2d_4/kernel, conv2d_4/kernel/Adam, conv2d_4/kernel/Adam_1, conv2d_5/bias, conv2d_5/bias/Adam, conv2d_5/bias/Adam_1, conv2d_5/kernel, conv2d_5/kernel/Adam, conv2d_5/kernel/Adam_1, conv2d_6/bias, conv2d_6/bias/Adam, conv2d_6/bias/Adam_1, conv2d_6/kernel, conv2d_6/kernel/Adam, conv2d_6/kernel/Adam_1, conv2d_7/bias, conv2d_7/bias/Adam, conv2d_7/bias/Adam_1, conv2d_7/kernel, conv2d_7/kernel/Adam, conv2d_7/kernel/Adam_1, conv2d_8/bias, conv2d_8/bias/Adam, conv2d_8/bias/Adam_1, conv2d_8/kernel, conv2d_8/kernel/Adam, conv2d_8/kernel/Adam_1, conv2d_9/bias, conv2d_9/bias/Adam, conv2d_9/bias/Adam_1, conv2d_9/kernel, conv2d_9/kernel/Adam, conv2d_9/kernel/Adam_1)]]\n\nCaused by op 'save/SaveV2', defined at:\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-388a246ecaff>\", line 2, in <module>\n    yolo_object.train()\n  File \"<ipython-input-2-37f96ed824a0>\", line 258, in train\n    saver = tf.train.Saver()\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1338, in __init__\n    self.build()\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1347, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1384, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 832, in _build_internal\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 350, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 266, in save_op\n    tensors)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1800, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'save/SaveV2': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\nRegistered kernels:\n  device='CPU'\n\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/device:GPU:0\"](save/Const, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, batch_normalization/beta, batch_normalization/beta/Adam, batch_normalization/beta/Adam_1, batch_normalization/gamma, batch_normalization/gamma/Adam, batch_normalization/gamma/Adam_1, batch_normalization/moving_mean, batch_normalization/moving_variance, batch_normalization_1/beta, batch_normalization_1/beta/Adam, batch_normalization_1/beta/Adam_1, batch_normalization_1/gamma, batch_normalization_1/gamma/Adam, batch_normalization_1/gamma/Adam_1, batch_normalization_1/moving_mean, batch_normalization_1/moving_variance, batch_normalization_10/beta, batch_normalization_10/gamma, batch_normalization_10/moving_mean, batch_normalization_10/moving_variance, batch_normalization_11/beta, batch_normalization_11/beta/Adam, batch_normalization_11/beta/Adam_1, batch_normalization_11/gamma, batch_normalization_11/gamma/Adam, batch_normalization_11/gamma/Adam_1, batch_normalization_11/moving_mean, batch_normalization_11/moving_variance, batch_normalization_12/beta, batch_normalization_12/beta/Adam, batch_normalization_12/beta/Adam_1, batch_normalization_12/gamma, batch_normalization_12/gamma/Adam, batch_normalization_12/gamma/Adam_1, batch_normalization_12/moving_mean, batch_normalization_12/moving_variance, batch_normalization_13/beta, batch_normalization_13/beta/Adam, batch_normalization_13/beta/Adam_1, batch_normalization_13/gamma, batch_normalization_13/gamma/Adam, batch_normalization_13/gamma/Adam_1, batch_normalization_13/moving_mean, batch_normalization_13/moving_variance, batch_normalization_14/beta, batch_normalization_14/beta/Adam, batch_normalization_14/beta/Adam_1, batch_normalization_14/gamma, batch_normalization_14/gamma/Adam, batch_normalization_14/gamma/Adam_1, batch_normalization_14/moving_mean, batch_normalization_14/moving_variance, batch_normalization_15/beta, batch_normalization_15/beta/Adam, batch_normalization_15/beta/Adam_1, batch_normalization_15/gamma, batch_normalization_15/gamma/Adam, batch_normalization_15/gamma/Adam_1, batch_normalization_15/moving_mean, batch_normalization_15/moving_variance, batch_normalization_16/beta, batch_normalization_16/beta/Adam, batch_normalization_16/beta/Adam_1, batch_normalization_16/gamma, batch_normalization_16/gamma/Adam, batch_normalization_16/gamma/Adam_1, batch_normalization_16/moving_mean, batch_normalization_16/moving_variance, batch_normalization_17/beta, batch_normalization_17/beta/Adam, batch_normalization_17/beta/Adam_1, batch_normalization_17/gamma, batch_normalization_17/gamma/Adam, batch_normalization_17/gamma/Adam_1, batch_normalization_17/moving_mean, batch_normalization_17/moving_variance, batch_normalization_18/beta, batch_normalization_18/beta/Adam, batch_normalization_18/beta/Adam_1, batch_normalization_18/gamma, batch_normalization_18/gamma/Adam, batch_normalization_18/gamma/Adam_1, batch_normalization_18/moving_mean, batch_normalization_18/moving_variance, batch_normalization_19/beta, batch_normalization_19/beta/Adam, batch_normalization_19/beta/Adam_1, batch_normalization_19/gamma, batch_normalization_19/gamma/Adam, batch_normalization_19/gamma/Adam_1, batch_normalization_19/moving_mean, batch_normalization_19/moving_variance, batch_normalization_2/beta, batch_normalization_2/beta/Adam, batch_normalization_2/beta/Adam_1, batch_normalization_2/gamma, batch_normalization_2/gamma/Adam, batch_normalization_2/gamma/Adam_1, batch_normalization_2/moving_mean, batch_normalization_2/moving_variance, batch_normalization_20/beta, batch_normalization_20/beta/Adam, batch_normalization_20/beta/Adam_1, batch_normalization_20/gamma, batch_normalization_20/gamma/Adam, batch_normalization_20/gamma/Adam_1, batch_normalization_20/moving_mean, batch_normalization_20/moving_variance, batch_normalization_3/beta, batch_normalization_3/beta/Adam, batch_normalization_3/beta/Adam_1, batch_normalization_3/gamma, batch_normalization_3/gamma/Adam, batch_normalization_3/gamma/Adam_1, batch_normalization_3/moving_mean, batch_normalization_3/moving_variance, batch_normalization_4/beta, batch_normalization_4/beta/Adam, batch_normalization_4/beta/Adam_1, batch_normalization_4/gamma, batch_normalization_4/gamma/Adam, batch_normalization_4/gamma/Adam_1, batch_normalization_4/moving_mean, batch_normalization_4/moving_variance, batch_normalization_5/beta, batch_normalization_5/beta/Adam, batch_normalization_5/beta/Adam_1, batch_normalization_5/gamma, batch_normalization_5/gamma/Adam, batch_normalization_5/gamma/Adam_1, batch_normalization_5/moving_mean, batch_normalization_5/moving_variance, batch_normalization_6/beta, batch_normalization_6/beta/Adam, batch_normalization_6/beta/Adam_1, batch_normalization_6/gamma, batch_normalization_6/gamma/Adam, batch_normalization_6/gamma/Adam_1, batch_normalization_6/moving_mean, batch_normalization_6/moving_variance, batch_normalization_7/beta, batch_normalization_7/beta/Adam, batch_normalization_7/beta/Adam_1, batch_normalization_7/gamma, batch_normalization_7/gamma/Adam, batch_normalization_7/gamma/Adam_1, batch_normalization_7/moving_mean, batch_normalization_7/moving_variance, batch_normalization_8/beta, batch_normalization_8/beta/Adam, batch_normalization_8/beta/Adam_1, batch_normalization_8/gamma, batch_normalization_8/gamma/Adam, batch_normalization_8/gamma/Adam_1, batch_normalization_8/moving_mean, batch_normalization_8/moving_variance, batch_normalization_9/beta, batch_normalization_9/beta/Adam, batch_normalization_9/beta/Adam_1, batch_normalization_9/gamma, batch_normalization_9/gamma/Adam, batch_normalization_9/gamma/Adam_1, batch_normalization_9/moving_mean, batch_normalization_9/moving_variance, beta1_power, beta2_power, conv2d/bias, conv2d/bias/Adam, conv2d/bias/Adam_1, conv2d/kernel, conv2d/kernel/Adam, conv2d/kernel/Adam_1, conv2d_1/bias, conv2d_1/bias/Adam, conv2d_1/bias/Adam_1, conv2d_1/kernel, conv2d_1/kernel/Adam, conv2d_1/kernel/Adam_1, conv2d_10/bias, conv2d_10/kernel, conv2d_11/bias, conv2d_11/bias/Adam, conv2d_11/bias/Adam_1, conv2d_11/kernel, conv2d_11/kernel/Adam, conv2d_11/kernel/Adam_1, conv2d_12/bias, conv2d_12/bias/Adam, conv2d_12/bias/Adam_1, conv2d_12/kernel, conv2d_12/kernel/Adam, conv2d_12/kernel/Adam_1, conv2d_13/bias, conv2d_13/bias/Adam, conv2d_13/bias/Adam_1, conv2d_13/kernel, conv2d_13/kernel/Adam, conv2d_13/kernel/Adam_1, conv2d_14/bias, conv2d_14/bias/Adam, conv2d_14/bias/Adam_1, conv2d_14/kernel, conv2d_14/kernel/Adam, conv2d_14/kernel/Adam_1, conv2d_15/bias, conv2d_15/bias/Adam, conv2d_15/bias/Adam_1, conv2d_15/kernel, conv2d_15/kernel/Adam, conv2d_15/kernel/Adam_1, conv2d_16/bias, conv2d_16/bias/Adam, conv2d_16/bias/Adam_1, conv2d_16/kernel, conv2d_16/kernel/Adam, conv2d_16/kernel/Adam_1, conv2d_17/bias, conv2d_17/bias/Adam, conv2d_17/bias/Adam_1, conv2d_17/kernel, conv2d_17/kernel/Adam, conv2d_17/kernel/Adam_1, conv2d_18/bias, conv2d_18/bias/Adam, conv2d_18/bias/Adam_1, conv2d_18/kernel, conv2d_18/kernel/Adam, conv2d_18/kernel/Adam_1, conv2d_19/bias, conv2d_19/bias/Adam, conv2d_19/bias/Adam_1, conv2d_19/kernel, conv2d_19/kernel/Adam, conv2d_19/kernel/Adam_1, conv2d_2/bias, conv2d_2/bias/Adam, conv2d_2/bias/Adam_1, conv2d_2/kernel, conv2d_2/kernel/Adam, conv2d_2/kernel/Adam_1, conv2d_20/bias, conv2d_20/bias/Adam, conv2d_20/bias/Adam_1, conv2d_20/kernel, conv2d_20/kernel/Adam, conv2d_20/kernel/Adam_1, conv2d_21/bias, conv2d_21/bias/Adam, conv2d_21/bias/Adam_1, conv2d_21/kernel, conv2d_21/kernel/Adam, conv2d_21/kernel/Adam_1, conv2d_3/bias, conv2d_3/bias/Adam, conv2d_3/bias/Adam_1, conv2d_3/kernel, conv2d_3/kernel/Adam, conv2d_3/kernel/Adam_1, conv2d_4/bias, conv2d_4/bias/Adam, conv2d_4/bias/Adam_1, conv2d_4/kernel, conv2d_4/kernel/Adam, conv2d_4/kernel/Adam_1, conv2d_5/bias, conv2d_5/bias/Adam, conv2d_5/bias/Adam_1, conv2d_5/kernel, conv2d_5/kernel/Adam, conv2d_5/kernel/Adam_1, conv2d_6/bias, conv2d_6/bias/Adam, conv2d_6/bias/Adam_1, conv2d_6/kernel, conv2d_6/kernel/Adam, conv2d_6/kernel/Adam_1, conv2d_7/bias, conv2d_7/bias/Adam, conv2d_7/bias/Adam_1, conv2d_7/kernel, conv2d_7/kernel/Adam, conv2d_7/kernel/Adam_1, conv2d_8/bias, conv2d_8/bias/Adam, conv2d_8/bias/Adam_1, conv2d_8/kernel, conv2d_8/kernel/Adam, conv2d_8/kernel/Adam_1, conv2d_9/bias, conv2d_9/bias/Adam, conv2d_9/bias/Adam_1, conv2d_9/kernel, conv2d_9/kernel/Adam, conv2d_9/kernel/Adam_1)]]\n"
     ]
    }
   ],
   "source": [
    "yolo_object = YOLO(2)\n",
    "yolo_object.train()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw_bndbox\n",
    "def draw_bndbox(label_path, image_path):\n",
    "    tree = parse(label_path)\n",
    "    note = tree.getroot()\n",
    "    #tree.dump()\n",
    "    child = note.getchildren()\n",
    "    #data = dump(note)\n",
    "    for attribute in child:\n",
    "        if(attribute.tag == \"object\"):\n",
    "            child2 = attribute.getchildren()\n",
    "            for attribute2 in child2:\n",
    "                if(attribute2.tag == \"bndbox\"):\n",
    "                    child3 = attribute2.getchildren()\n",
    "                    xmin = child3[0]\n",
    "                    ymin = child3[1]\n",
    "                    xmax = child3[2]\n",
    "                    ymax = child3[3]\n",
    "\n",
    "    x_min_pos = int(xmin.text)\n",
    "    y_min_pos = int(ymin.text)\n",
    "    x_max_pos = int(xmax.text)\n",
    "    y_max_pos = int(ymax.text)\n",
    "    start = (x_min_pos, y_min_pos)\n",
    "    end = (x_max_pos, y_max_pos)\n",
    "    color = (0, 0, 255)\n",
    "    thickness = 2\n",
    "\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    img = cv2.rectangle(img, start, end, color, thickness)\n",
    "    \n",
    "    return img\n",
    "\n",
    "#사용 예\n",
    "xml_path = \"./data/data_pascal/VOCdevkit/VOC2012/Annotations/2007_000027.xml\"\n",
    "img_path = \"./data/data_pascal/VOCdevkit/VOC2012/JPEGImages/2007_000027.jpg\"\n",
    "\n",
    "\n",
    "img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "img = draw_bndbox(xml_path, img_path)\n",
    "cv2.imshow('image', img)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data 받아와서 배치 만드는 곳\n",
    "def make_batch():\n",
    "    classes = [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "    xml_data = []\n",
    "    jpg_data = []\n",
    "    index = 0\n",
    "    for root, dirs, files in os.walk('./VOCdevkit/VOC2012'):\n",
    "        for fname in files:\n",
    "            full_fname = os.path.join(root, fname)\n",
    "            full_fname = full_fname.replace(\"\\\\\", \"/\")\n",
    "            if(index < 17125):\n",
    "                xml_data.append(full_fname)\n",
    "            if(index >= 17227 and index < 34352):\n",
    "                jpg_data.append(full_fname)\n",
    "            index = index + 1\n",
    "\n",
    "    batch_size = 4\n",
    "    data_index = np.arange(0, 17125)\n",
    "    np.random.shuffle(data_index)\n",
    "    data_index = data_index[0:batch_size]\n",
    "    shuffled_input_data = [jpg_data[i] for i in data_index]\n",
    "    shuffled_label_data = [xml_data[i] for i in data_index]\n",
    "    \n",
    "    bnd_batch = []\n",
    "    for i in range(batch_size):\n",
    "        tree = parse(shuffled_label_data[i])\n",
    "        note = tree.getroot()\n",
    "        #tree.dump()\n",
    "        child = note.getchildren()\n",
    "        #data = dump(note)\n",
    "        bnd_data = []\n",
    "        for attribute in child:\n",
    "            if(attribute.tag == \"object\"):\n",
    "                child2 = attribute.getchildren()\n",
    "                for attribute2 in child2:\n",
    "                    if(attribute2.tag == \"name\"):\n",
    "                        class_name = attribute2\n",
    "                        classification = class_name.text\n",
    "                        bnd_data.append(classification)\n",
    "                    if(attribute2.tag == \"bndbox\"):\n",
    "                        child3 = attribute2.getchildren()\n",
    "                        xmin = child3[0]\n",
    "                        ymin = child3[1]\n",
    "                        xmax = child3[2]\n",
    "                        ymax = child3[3]\n",
    "\n",
    "                        xmin = int(xmin.text)\n",
    "                        ymin = int(ymin.text)\n",
    "                        xmax = int(xmax.text)\n",
    "                        ymax = int(ymax.text)\n",
    "\n",
    "                        width  = xmax - xmin\n",
    "                        height = ymax - ymin\n",
    "                        x_pos = xmax - width//2\n",
    "                        y_pos = ymax - height//2\n",
    "\n",
    "                        bnd_data.append(x_pos)\n",
    "                        bnd_data.append(y_pos)\n",
    "                        bnd_data.append(width)\n",
    "                        bnd_data.append(height)\n",
    "\n",
    "        #tmp = bnd_data[0]\n",
    "        #bnd_data[0] = bnd_data[1]\n",
    "        #bnd_data[1] = bnd_data[2]\n",
    "        #bnd_data[2] = bnd_data[3]\n",
    "        #bnd_data[3] = bnd_data[4]\n",
    "        #bnd_data[4] = tmp\n",
    "        \n",
    "        bnd_batch.append(bnd_data)\n",
    "    input_data = [None] * batch_size\n",
    "    label_data = [None] * batch_size\n",
    "    for i in range(batch_size):\n",
    "        input_data[i] = cv2.imread(shuffled_input_data[i], cv2.IMREAD_COLOR)\n",
    "        \n",
    "        \n",
    "    return input_data, bnd_batch#batch 형태\n",
    "batch_img_data, batch_bnd_data = make_batch()\n",
    "batch_img_data\n",
    "batch_bnd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw_bndbox\n",
    "tree = parse(\"./VOCdevkit/VOC2012/Annotations/2007_000027.xml\")\n",
    "note = tree.getroot()\n",
    "#tree.dump()\n",
    "child = note.getchildren()\n",
    "#data = dump(note)\n",
    "bnd_data = []\n",
    "for attribute in child:\n",
    "    if(attribute.tag == \"object\"):\n",
    "        child2 = attribute.getchildren()\n",
    "        for attribute2 in child2:\n",
    "            if(attribute2.tag == \"name\"):\n",
    "                class_name = attribute2\n",
    "                classification = class_name.text\n",
    "                bnd_data.append(classification)\n",
    "            if(attribute2.tag == \"bndbox\"):\n",
    "                child3 = attribute2.getchildren()\n",
    "                xmin = child3[0]\n",
    "                ymin = child3[1]\n",
    "                xmax = child3[2]\n",
    "                ymax = child3[3]\n",
    "                \n",
    "                xmin = int(xmin.text)\n",
    "                ymin = int(ymin.text)\n",
    "                xmax = int(xmax.text)\n",
    "                ymax = int(ymax.text)\n",
    "                \n",
    "                width  = xmax - xmin\n",
    "                height = ymax - ymin\n",
    "                x_pos = xmax - width//2\n",
    "                y_pos = ymax - height//2\n",
    "                \n",
    "                bnd_data.append(x_pos)\n",
    "                bnd_data.append(y_pos)\n",
    "                bnd_data.append(width)\n",
    "                bnd_data.append(height)\n",
    "                \n",
    "tmp = bnd_data[0]\n",
    "bnd_data[0] = bnd_data[1]\n",
    "bnd_data[1] = bnd_data[2]\n",
    "bnd_data[2] = bnd_data[3]\n",
    "bnd_data[3] = bnd_data[4]\n",
    "bnd_data[4] = tmp\n",
    "\n",
    "print(bnd_data)\n",
    "#print(classification)\n",
    "#data = dump(note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pickle\n",
    "import os\n",
    "from os import listdir, getcwd\n",
    "from os.path import join\n",
    "\n",
    "sets=[('2012', 'train'), ('2012', 'val'), ('2007', 'train'), ('2007', 'val'), ('2007', 'test')]\n",
    "\n",
    "classes = [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "\n",
    "def convert(size, box):\n",
    "    dw = 1./size[0]\n",
    "    dh = 1./size[1]\n",
    "    x = (box[0] + box[1])/2.0\n",
    "    y = (box[2] + box[3])/2.0\n",
    "    w = box[1] - box[0]\n",
    "    h = box[3] - box[2]\n",
    "    x = x*dw\n",
    "    w = w*dw\n",
    "    y = y*dh\n",
    "    h = h*dh\n",
    "    return (x,y,w,h)\n",
    "\n",
    "def convert_annotation(year, image_id):\n",
    "    in_file = open('VOCdevkit/VOC%s/Annotations/%s.xml'%(year, image_id))\n",
    "    out_file = open('VOCdevkit/VOC%s/labels/%s.txt'%(year, image_id), 'w')\n",
    "    tree=ET.parse(in_file)\n",
    "    root = tree.getroot()\n",
    "    size = root.find('size')\n",
    "    w = int(size.find('width').text)\n",
    "    h = int(size.find('height').text)\n",
    "\n",
    "    for obj in root.iter('object'):\n",
    "        difficult = obj.find('difficult').text\n",
    "        cls = obj.find('name').text\n",
    "        if cls not in classes or int(difficult) == 1:\n",
    "            continue\n",
    "        cls_id = classes.index(cls)\n",
    "        xmlbox = obj.find('bndbox')\n",
    "        b = (float(xmlbox.find('xmin').text), float(xmlbox.find('xmax').text), float(xmlbox.find('ymin').text), float(xmlbox.find('ymax').text))\n",
    "        bb = convert((w,h), b)\n",
    "        out_file.write(str(cls_id) + \" \" + \" \".join([str(a) for a in bb]) + '\\n')\n",
    "\n",
    "wd = getcwd()\n",
    "\n",
    "for year, image_set in sets:\n",
    "    if not os.path.exists('VOCdevkit/VOC%s/labels/'%(year)):\n",
    "        os.makedirs('VOCdevkit/VOC%s/labels/'%(year))\n",
    "    image_ids = open('VOCdevkit/VOC%s/ImageSets/Main/%s.txt'%(year, image_set)).read().strip().split()\n",
    "    list_file = open('%s_%s.txt'%(year, image_set), 'w')\n",
    "    for image_id in image_ids:\n",
    "        list_file.write('%s/VOCdevkit/VOC%s/JPEGImages/%s.jpg\\n'%(wd, year, image_id))\n",
    "        convert_annotation(year, image_id)\n",
    "    list_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch():\n",
    "    xml_data = []\n",
    "    jpg_data = []\n",
    "    index = 0\n",
    "    for root, dirs, files in os.walk('./VOCdevkit'):\n",
    "        for fname in files:\n",
    "            full_fname = os.path.join(root, fname)\n",
    "            full_fname = full_fname.replace(\"\\\\\", \"/\")\n",
    "            if(index < 17125):\n",
    "                xml_data.append(full_fname)\n",
    "            if(index >= 17227 and index < 34352):\n",
    "                jpg_data.append(full_fname)\n",
    "            index = index + 1\n",
    "\n",
    "    batch_size = 4\n",
    "    data_index = np.arange(0, 17125)\n",
    "    np.random.shuffle(data_index)\n",
    "    data_index = data_index[0:batch_size]\n",
    "    shuffled_input_data = [jpg_data[i] for i in data_index]\n",
    "    shuffled_label_data = [xml_data[i] for i in data_index]\n",
    "    \n",
    "    bnd_batch = []\n",
    "    for i in range(batch_size):\n",
    "        tree = parse(shuffled_label_data[i])\n",
    "        note = tree.getroot()\n",
    "        #tree.dump()\n",
    "        child = note.getchildren()\n",
    "        #data = dump(note)\n",
    "        bnd_data = []\n",
    "        for attribute in child:\n",
    "            if(attribute.tag == \"object\"):\n",
    "                child2 = attribute.getchildren()\n",
    "                for attribute2 in child2:\n",
    "                    if(attribute2.tag == \"name\"):\n",
    "                        class_name = attribute2\n",
    "                        classification = class_name.text\n",
    "                        bnd_data.append(classification)\n",
    "                    if(attribute2.tag == \"bndbox\"):\n",
    "                        child3 = attribute2.getchildren()\n",
    "                        xmin = child3[0]\n",
    "                        ymin = child3[1]\n",
    "                        xmax = child3[2]\n",
    "                        ymax = child3[3]\n",
    "\n",
    "                        xmin = int(xmin.text)\n",
    "                        ymin = int(ymin.text)\n",
    "                        xmax = int(xmax.text)\n",
    "                        ymax = int(ymax.text)\n",
    "\n",
    "                        width  = xmax - xmin\n",
    "                        height = ymax - ymin\n",
    "                        x_pos = xmax - width//2\n",
    "                        y_pos = ymax - height//2\n",
    "\n",
    "                        bnd_data.append(x_pos)\n",
    "                        bnd_data.append(y_pos)\n",
    "                        bnd_data.append(width)\n",
    "                        bnd_data.append(height)\n",
    "\n",
    "        tmp = bnd_data[0]\n",
    "        bnd_data[0] = bnd_data[1]\n",
    "        bnd_data[1] = bnd_data[2]\n",
    "        bnd_data[2] = bnd_data[3]\n",
    "        bnd_data[3] = bnd_data[4]\n",
    "        bnd_data[4] = tmp\n",
    "        \n",
    "        bnd_batch.append(bnd_data)\n",
    "    input_data = [None] * batch_size\n",
    "    label_data = [None] * batch_size\n",
    "    for i in range(batch_size):\n",
    "        input_data[i] = cv2.imread(shuffled_input_data[i], cv2.IMREAD_COLOR)\n",
    "        \n",
    "        \n",
    "    return input_data, bnd_batch#batch 형태\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def yolo_loss(self, pred, label):\n",
    "        mask = slice_tensor(label, 5)\n",
    "        label = slice_tensor(label, 0, 4)\n",
    "\n",
    "        mask = tf.cast(tf.reshape(mask, shape=(-1, 13, 13, 5)),tf.bool)\n",
    "\n",
    "        with tf.name_scope('mask'):\n",
    "            masked_label = tf.boolean_mask(label, mask)\n",
    "            masked_pred = tf.boolean_mask(pred, mask)\n",
    "            neg_masked_pred = tf.boolean_mask(pred, tf.logical_not(mask))\n",
    "\n",
    "        with tf.name_scope('pred'):\n",
    "            masked_pred_xy = tf.sigmoid(slice_tensor(masked_pred, 0, 1))\n",
    "            masked_pred_wh = tf.exp(slice_tensor(masked_pred, 2, 3))\n",
    "            masked_pred_o = tf.sigmoid(slice_tensor(masked_pred, 4))\n",
    "            masked_pred_no_o = tf.sigmoid(slice_tensor(neg_masked_pred, 4))\n",
    "            masked_pred_c = tf.nn.softmax(slice_tensor(masked_pred, 5, -1))\n",
    "\n",
    "        with tf.name_scope('lab'):\n",
    "            masked_label_xy = slice_tensor(masked_label, 0, 1)\n",
    "            masked_label_wh = slice_tensor(masked_label, 2, 3)\n",
    "            masked_label_c = slice_tensor(masked_label, 4)\n",
    "            masked_label_c_vec = tf.reshape(tf.one_hot(tf.cast(masked_label_c, tf.int32), depth=20), shape=(-1, 20))\n",
    "\n",
    "        with tf.name_scope('merge'):\n",
    "            with tf.name_scope('loss_xy'):\n",
    "                loss_xy = tf.reduce_sum(tf.square(masked_pred_xy-masked_label_xy))\n",
    "            with tf.name_scope('loss_wh'):\n",
    "                loss_wh = tf.reduce_sum(tf.square(masked_pred_wh-masked_label_wh))\n",
    "            with tf.name_scope('loss_obj'):\n",
    "                loss_obj = tf.reduce_sum(tf.square(masked_pred_o - 1))\n",
    "            with tf.name_scope('loss_no_obj'):\n",
    "                loss_no_obj = tf.reduce_sum(tf.square(masked_pred_no_o))\n",
    "            with tf.name_scope('loss_class'):\n",
    "                loss_c = tf.reduce_sum(tf.square(masked_pred_c - masked_label_c_vec))\n",
    "\n",
    "            loss = 5.0 * (loss_xy + loss_wh) + loss_obj + 0.5 * loss_no_obj + loss_c\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw_bndbox\n",
    "def draw_bndbox(label_path, image_path):\n",
    "    tree = parse(label_path)\n",
    "    note = tree.getroot()\n",
    "    #tree.dump()\n",
    "    child = note.getchildren()\n",
    "    #data = dump(note)\n",
    "    for attribute in child:\n",
    "        if(attribute.tag == \"object\"):\n",
    "            child2 = attribute.getchildren()\n",
    "            for attribute2 in child2:\n",
    "                if(attribute2.tag == \"bndbox\"):\n",
    "                    child3 = attribute2.getchildren()\n",
    "                    xmin = child3[0]\n",
    "                    ymin = child3[1]\n",
    "                    xmax = child3[2]\n",
    "                    ymax = child3[3]\n",
    "\n",
    "    x_min_pos = int(xmin.text)\n",
    "    y_min_pos = int(ymin.text)\n",
    "    x_max_pos = int(xmax.text)\n",
    "    y_max_pos = int(ymax.text)\n",
    "    start = (x_min_pos, y_min_pos)\n",
    "    end = (x_max_pos, y_max_pos)\n",
    "    color = (0, 0, 255)\n",
    "    thickness = 2\n",
    "\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    img = cv2.rectangle(img, start, end, color, thickness)\n",
    "    \n",
    "    return img\n",
    "\n",
    "#사용 예\n",
    "xml_path = \"./VOCdevkit/VOCdevkit/VOC2012/Annotations/2007_000027.xml\"\n",
    "img_path = \"./VOCdevkit/VOCdevkit/VOC2012/JPEGImages/2007_000027.jpg\"\n",
    "\n",
    "\n",
    "img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "img = draw_bndbox(xml_path, img_path)\n",
    "cv2.imshow('image', img)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
